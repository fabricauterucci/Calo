# ğŸ¯ GuÃ­a RÃ¡pida: Usar el Scraper

## âœ… Todo listo y funcionando:

- âœ… Entorno virtual creado (`venv/`)
- âœ… Scrapy + BeautifulSoup instalado
- âœ… Selenium + ChromeDriver funcionando
- âœ… FastAPI configurado
- âœ… Base de datos SQLite configurada
- âœ… Frontend listo

---

## ğŸš€ Uso RÃ¡pido

### 1ï¸âƒ£ Scraping SIN Selenium (mÃ¡s rÃ¡pido)

```bash
source venv/bin/activate

# Probar con sitios que no bloquean
scrapy crawl argenprop
scrapy crawl remax
scrapy crawl mapropiedades
scrapy crawl lacapital
scrapy crawl bienesrosario
```

### 2ï¸âƒ£ Scraping CON Selenium (para sitios que bloquean)

```bash
source venv/bin/activate

# ZonaProp con Selenium (evita error 403)
scrapy crawl zonaprop_selenium
```

### 3ï¸âƒ£ Iniciar API

```bash
# En otra terminal
source venv/bin/activate
cd api
uvicorn main:app --reload
```

Visita: http://localhost:8000/docs

### 4ï¸âƒ£ Abrir Frontend

```bash
# En otra terminal
cd frontend
python -m http.server 8080
```

Visita: http://localhost:8080

---

## ğŸ“Š Ver datos scrapeados

```bash
# Con SQLite Browser (instalar: sudo apt install sqlitebrowser)
sqlitebrowser propiedades.db

# O directamente con sqlite3
sqlite3 propiedades.db "SELECT COUNT(*) FROM propiedades;"
sqlite3 propiedades.db "SELECT titulo, precio, barrio FROM propiedades LIMIT 5;"
```

---

## ğŸ”§ Comandos Ãštiles

```bash
# Ver estadÃ­sticas del scraping
scrapy crawl zonaprop_selenium -L INFO | grep "âœ…"

# Guardar en JSON ademÃ¡s de DB
scrapy crawl argenprop -o salida.json

# Limitar cantidad de pÃ¡ginas
scrapy crawl zonaprop_selenium -s CLOSESPIDER_PAGECOUNT=5

# Ver solo errores
scrapy crawl remax 2>&1 | grep ERROR
```

---

## ğŸ® Spiders Disponibles

| Spider | Selenium | Velocidad | Estado |
|--------|----------|-----------|--------|
| `zonaprop` | âŒ | âš¡âš¡âš¡ | Error 403 |
| `zonaprop_selenium` | âœ… | ğŸ¢ | **Funciona** |
| `argenprop` | âŒ | âš¡âš¡âš¡ | Probar |
| `remax` | âŒ | âš¡âš¡âš¡ | Probar |
| `mapropiedades` | âŒ | âš¡âš¡âš¡ | Probar |
| `lacapital` | âŒ | âš¡âš¡âš¡ | Probar |
| `bienesrosario` | âŒ | âš¡âš¡âš¡ | Probar |

---

## ğŸ’¡ Tips

1. **Empieza con spiders sin Selenium** - Son mÃ¡s rÃ¡pidos
2. **Si falla (403, sin datos)** - Usa versiÃ³n `_selenium`
3. **No corras todos a la vez** - Los sitios pueden bloquearte
4. **Scraping gradual**: Haz un sitio a la vez, espera un poco entre cada uno
5. **Revisa los datos**: Algunos selectores pueden necesitar ajustes

---

## ğŸ› Problemas comunes

**No aparecen datos en la API/Frontend**:
```bash
# Verifica que hay datos
sqlite3 propiedades.db "SELECT COUNT(*) FROM propiedades;"

# Verifica que la API estÃ© corriendo
curl http://localhost:8000/stats
```

**Selenium falla**:
```bash
# Verifica chromedriver
chromedriver --version
chromium --version

# DeberÃ­an ser versiones compatibles
```

**Error de mÃ³dulos**:
```bash
source venv/bin/activate  # Â¡SIEMPRE activar primero!
pip install -r requirements.txt
```

---

## ğŸ¯ Flujo de trabajo recomendado

```bash
# Terminal 1: Scraping
source venv/bin/activate
scrapy crawl zonaprop_selenium  # Tarda ~5-10 min

# Esperar que termine...
# Luego scrapear otros sitios
scrapy crawl argenprop
scrapy crawl remax

# Terminal 2: API (mientras scrapeas)
source venv/bin/activate
cd api
uvicorn main:app --reload

# Terminal 3: Frontend
cd frontend
python -m http.server 8080
```

Ahora puedes ir a http://localhost:8080 y ver las propiedades mientras se scrapean! ğŸ‰

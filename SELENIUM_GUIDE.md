# ğŸ¯ GuÃ­a: Scrapy + Selenium

## Â¿CuÃ¡ndo usar Selenium?

### âœ… USA Selenium SI:
- El precio/datos solo aparecen despuÃ©s de ejecutar JavaScript
- Hay "infinite scroll" o "lazy loading"
- El sitio detecta bots y bloquea requests normales (403, 429)
- Contenido cargado dinÃ¡micamente con AJAX

### âŒ NO uses Selenium SI:
- El HTML tiene toda la informaciÃ³n (mÃ¡s rÃ¡pido con requests)
- El sitio tiene API pÃºblica
- Puedes hacer scraping con headers mejorados

---

## ğŸ“¦ InstalaciÃ³n

```bash
# Activar entorno virtual
source venv/bin/activate

# Instalar Selenium
pip install -r requirements-selenium.txt
```

---

## ğŸ§ª Probar Selenium

```bash
# Test bÃ¡sico
scrapy crawl test_selenium

# Si funciona, verÃ¡s:
# âœ… Selenium estÃ¡ FUNCIONANDO
```

---

## ğŸ•·ï¸ Usar Selenium en un Spider

### OpciÃ³n 1: Spider completo con Selenium

```python
class MiSpider(scrapy.Spider):
    name = 'mi_spider'
    
    custom_settings = {
        'SELENIUM_ENABLED': True,  # âœ… Activar
        'DOWNLOADER_MIDDLEWARES': {
            'scraper.middlewares.SeleniumMiddleware': 800,
        },
    }
    
    def start_requests(self):
        yield scrapy.Request(
            'https://ejemplo.com',
            callback=self.parse,
            meta={
                'selenium': True,  # âœ… Usar Selenium
                'wait_for': '.product-list',  # Selector a esperar
                'wait_time': 3,  # Segundos extra
                'scroll': True  # Scroll para lazy loading
            }
        )
```

### OpciÃ³n 2: Selenium solo para requests especÃ­ficos

```python
class MiSpider(scrapy.Spider):
    # ... sin Selenium en custom_settings
    
    def parse(self, response):
        # Request normal (rÃ¡pido)
        yield scrapy.Request(url1, callback=self.parse_fast)
        
        # Request con Selenium (solo si es necesario)
        yield scrapy.Request(
            url2,
            callback=self.parse_selenium,
            meta={'selenium': True}
        )
```

---

## ğŸ® Ejemplos PrÃ¡cticos

### ZonaProp con Selenium (evita 403)
```bash
scrapy crawl zonaprop_selenium
```

### ZonaProp sin Selenium (mÃ¡s rÃ¡pido, puede fallar)
```bash
scrapy crawl zonaprop
```

---

## âš™ï¸ Opciones del middleware

```python
meta={
    'selenium': True,           # Activar Selenium para este request
    'wait_for': '.selector',    # Esperar a que aparezca este elemento
    'wait_time': 3,             # Segundos extra de espera
    'scroll': True,             # Hacer scroll (lazy loading)
}
```

---

## ğŸš€ Performance

| MÃ©todo | Velocidad | CPU | Memoria | CuÃ¡ndo usar |
|--------|-----------|-----|---------|-------------|
| **Requests** | âš¡âš¡âš¡ | Baja | Baja | HTML estÃ¡tico |
| **Selenium** | ğŸ¢ | Alta | Alta | JS dinÃ¡mico |

**Tip**: Combina ambos en el mismo spider para mÃ¡xima eficiencia.

---

## ğŸ› ï¸ Troubleshooting

### Error: ChromeDriver no encontrado
```bash
pip install webdriver-manager
```

### Error: Chrome no instalado
```bash
# Ubuntu/Debian
sudo apt update
sudo apt install chromium-browser

# O usar Chrome
wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb
sudo dpkg -i google-chrome-stable_current_amd64.deb
```

### Selenium muy lento
```python
custom_settings = {
    'DOWNLOAD_DELAY': 1,  # Reducir delay
    'CONCURRENT_REQUESTS': 1,  # Un solo request a la vez con Selenium
}
```

---

## ğŸ“ Logs

Cuando Selenium estÃ¡ activo verÃ¡s:
```
ğŸš€ Inicializando Selenium para spider: zonaprop_selenium
âœ… Selenium iniciado correctamente
ğŸŒ Usando Selenium para: https://...
ğŸ›‘ Cerrando Selenium
```

---

## ğŸ¯ Estrategia Recomendada

1. **Intenta primero sin Selenium** (zonaprop, argenprop, etc.)
2. **Si falla (403, sin datos)** â†’ usa versiÃ³n con Selenium
3. **Prueba selectores en la consola del navegador** antes de scrapear
4. **Combina**: listado con requests, detalles con Selenium si es necesario
